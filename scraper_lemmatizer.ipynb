{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "cuisines=['italian','chinese', 'mexican','indian','french','cajun','thai','japanese','greek','spanish','korean','vietnamese','moroccan','english','filipino','irish','jamaican','russian','brazilian']\n",
    "for cuisine in cuisines:\n",
    "    results=[]\n",
    "    for i in range(0, 100000, 500):\n",
    "        try:\n",
    "            r=requests.get(\"http://api.yummly.com/v1/api/recipes?_app_id=f61f4d8a&_app_key=3267b3d42b0792a7f508f33f3b9ac8f7&q=&allowedCuisine=cuisine%5Ecuisine-\"+cuisine+\"&maxResult=500&start=\"+str(i))\n",
    "        except:\n",
    "            print(cuisine, i)\n",
    "            continue\n",
    "        rj=r.json()\n",
    "        if rj['matches']:\n",
    "            results.extend(rj['matches'])\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    with open(cuisine+'.json', 'w') as fout:\n",
    "        json.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "cuisines=['italian','chinese', 'mexican','indian','french','cajun','thai','japanese','greek','spanish','korean','vietnamese','moroccan','english','filipino','irish','jamaican','russian','brazilian','train']\n",
    "lmtzr = WordNetLemmatizer()\n",
    "food={}\n",
    "singular=[]\n",
    "\n",
    "for cuisine in cuisines:\n",
    "    json_data=open(cuisine+\".json\").read()\n",
    "    data = json.loads(json_data)\n",
    "    for recipe in data:\n",
    "        newRecipe={}\n",
    "        temp=[]\n",
    "        if cuisine!='train':\n",
    "            temp.append(cuisine.upper())\n",
    "        else:\n",
    "            temp.append(recipe['cuisine'].upper())\n",
    "        for ing in recipe['ingredients']:\n",
    "            try:\n",
    "                single_form=food[ing]\n",
    "            except KeyError:\n",
    "                tokens = word_tokenize(ing)\n",
    "                tokens_pos = pos_tag(tokens)\n",
    "                food[ing]=' ' .join([lmtzr.lemmatize(item[0]).lower() if item[1]=='NNS' else item[0].lower() for item in tokens_pos])\n",
    "                single_form=food[ing]\n",
    "            temp.append(single_form)\n",
    "        newRecipe['ingredients']=temp\n",
    "        singular.append(newRecipe)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "with open('simplified.json', 'w') as fp:\n",
    "    json.dump(singular, fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
